Проверенные гипотезы:
1. Ручной отбор признаков, catboost, REE, 
2. Спрособы нормализации: Min-Max Scaling, StandardScaler, log
3. Понижением размерности: PCA, t-SNE, UMAP
4. Исскутвенное дообогощение данных: SMOTE и ADASYN 
5. Тестирование моделей: линейные (LogisticRegression), деревянные (RandomForestClassifier), ансамбль (LogisticRegression, RandomForestClassifier, XGBClassifier)
6*. Также можно добавить кросс-валидацию и пподбор гиперпараметров с помощью optuna для улучшения предсказаний модели

Работа далее для обучения модели с воспроизводимыми в проде результатами:
1. Сохранение весов модели
2. Создание сервиса и виртуального окружения для предскизаний, завервывание в docker и, если необходимо заливка на сервер
3. Данные диномическая вещь, поэтому настройка пайплана для дообучения модели 
4. Настройка мониторинга метрик 